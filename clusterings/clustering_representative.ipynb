{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "186a62f1-a483-441b-b09c-4832c72d8c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b48934da-e052-482a-a2fc-504dcd1967df",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_emd = pd.read_pickle('../clip-training/tweet_data_all_emb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f8f3139-0e14-47f1-8798-fa6e83054ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('../clip-training/train.pkl')\n",
    "df_val = pd.read_pickle('../clip-training/eval.pkl')\n",
    "df_test = pd.read_pickle('../clip-training/test_data.pkl')\n",
    "\n",
    "df_select = pd.concat([df_train, df_val])\n",
    "df_full = pd.concat([df_train, df_val, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95ca304b-b14d-4a4c-96a7-94211a04063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emd = clip_emd[clip_emd['tweet_id'].isin(df_select['tweet_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f755153-42d3-4362-a363-2b557fd41b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_emd = clip_emd[clip_emd['tweet_id'].isin(df_full['tweet_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31893762-ef5e-4ad0-89f4-2e4768923138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7dfc58c-0fc6-4395-951d-7642b24502dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c64efcf-969a-489c-8e87-a417cd2e6710",
   "metadata": {},
   "source": [
    "# Construction of Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96d3b81a-a9bc-4dc1-858b-52d99d1b08d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a1f25f2-1ffd-4b4c-8d2b-ab24f18a05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import igraph as ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ed419a5-6e49-4788-b827-6f5e5d0b5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar matrix as the graph adjacency matrix\n",
    "# cos_mat = util.cos_sim(train_emd['clip_imgs_sum_text_embeddings'].tolist(),train_emd['clip_imgs_sum_text_embeddings'].tolist()) \n",
    "# cos_mat = util.cos_sim(train_emd['clip_imgs_cat_text_embeddings'].tolist(),train_emd['clip_imgs_cat_text_embeddings'].tolist())\n",
    "cos_mat = util.cos_sim(full_emd['clip_imgs_sum_text_embeddings'].tolist(),full_emd['clip_imgs_sum_text_embeddings'].tolist()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c56026f8-4ab7-433f-8ed7-88348087bd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_copy = cos_mat.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "709e391f-ff5b-4481-afa7-a6a17ae74380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b61722ed-581a-4201-b1ed-32178dc94cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the threshold\n",
    "cos_copy[cos_copy < 0.85] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f26b4061-da17-4b40-a7af-10d6978892f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_numpy_array(cos_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "547322bd-18bd-4ff7-b8c2-83c0888ce046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_gpickle(G, \"graphSum85.gpickle\")\n",
    "# G = nx.read_gpickle(\"graph85.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6743d728-52cf-4f11-b55c-90f9f9d00e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ig.Graph.from_networkx(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f131715-11f1-4b62-a002-fd55a5d2ed94",
   "metadata": {},
   "source": [
    "# Leiden Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d3d853e-efd9-4566-8bd6-8cfaf88c6939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leidenalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e29213a5-44c2-47ff-bf95-75bc4d656bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = la.find_partition(g, la.ModularityVertexPartition, n_iterations=-1)\n",
    "optimizer = la.Optimiser()        \n",
    "diff = 1\n",
    "while diff > 0:\n",
    "    diff = optimizer.optimise_partition(communities,n_iterations=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a60a60c5-3a7c-403a-9a5b-3919eb39c749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8728de86-526c-47cf-8557-bb1bb8715d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_stats = {}\n",
    "k = 0\n",
    "for i in range(len(communities)):\n",
    "    if not dict_stats.get(len(communities[i])):\n",
    "        dict_stats[len(communities[i])] =0\n",
    "    dict_stats[len(communities[i])] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac4280dc-0200-4814-bb7e-de42d593e8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2760: 1, 1802: 1, 175: 1, 7: 1, 3: 8, 2: 12, 1: 208}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abfb7726-fa1d-4e64-a70a-6007975e72ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_com = {}\n",
    "k = 0\n",
    "for i in range(len(communities)):\n",
    "    if (len(communities[i])>=10):\n",
    "        dict_com[k] = train_emd.loc[train_emd.index[communities[i]]]\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62f80d2-b2da-45c7-bfe6-1923af6eded0",
   "metadata": {},
   "source": [
    "### leiden graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "749e9d08-3078-432e-9677-672d712280e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# communities[0][0].degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f560182-3c7e-435d-a931-d323d271b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_degree(cm_id, node_id):\n",
    "    return len(set(communities[cm_id]).intersection(communities.graph.neighborhood(communities[cm_id][node_id])))\n",
    "\n",
    "def cut_edges(cm_id, node_id):\n",
    "    \n",
    "    global_id = communities[cm_id][node_id]\n",
    "    neighbors_within_cluster = set(communities[cm_id]).intersection(communities.graph.neighborhood(communities[cm_id][node_id]))\n",
    "    edges, values = np.argsort(cos_copy[global_id][list(neighbors_within_cluster)])[-100:][::-1], np.sort(cos_copy[global_id][list(neighbors_within_cluster)])[-100:][::-1]\n",
    "    edges = [e for e, v in zip(edges, values) if v>0 and e!=global_id]\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def get_more_edges(cm_id, node_id,similarity_matrix):\n",
    "    neighbors_within_cluster = set(communities[cm_id]).intersection(communities.graph.neighborhood(communities[cm_id][node_id]))\n",
    "    global_id = communities[cm_id][node_id]\n",
    "    edges, values = np.argsort(similarity_matrix[global_id])[-10:][::-1], np.sort(similarity_matrix[global_id])[-10:][::-1]\n",
    "    edges = [e for e, v in zip(edges, values) if e!=global_id]\n",
    "    return edges\n",
    "def get_edges(cm_id, node_id):\n",
    "    global_id = communities[cm_id][node_id]\n",
    "    edges = [e for e in communities.graph.neighborhood(communities[cm_id][node_id]) if e!=global_id]\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e57d84bf-65eb-45df-b6a5-a90289756614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbors_within_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1220619-9004-40c0-9c57-007fbfe8489e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "232it [02:09,  1.79it/s]\n"
     ]
    }
   ],
   "source": [
    "gnn_graph = nx.Graph()\n",
    "\n",
    "# similar matrix as the graph adjacency matrix\n",
    "# similarity_matrix = util.cos_sim(train_emd['clip_imgs_sum_text_embeddings'].tolist(),train_emd['clip_imgs_sum_text_embeddings'].tolist()).detach().cpu().numpy()\n",
    "similarity_matrix = util.cos_sim(full_emd['clip_imgs_sum_text_embeddings'].tolist(),full_emd['clip_imgs_sum_text_embeddings'].tolist()).detach().cpu().numpy()\n",
    "\n",
    "# For each community (i.e., cluster)\n",
    "for cm_id , communitie in tqdm(enumerate(communities)):\n",
    "    # for each node within the cluster\n",
    "    for node_id, global_id in enumerate(communitie):\n",
    "        \n",
    "        # Check if the node degree is higher than 100\n",
    "        if get_degree(cm_id, node_id) > 100:\n",
    "            # cut edges\n",
    "            edges = cut_edges(cm_id, node_id)\n",
    "            for e in edges:\n",
    "                # Fix to tweetID\n",
    "#                 gnn_graph.add_edge(train_emd.iloc[global_id]['tweet_id'], train_emd.iloc[e]['tweet_id'])\n",
    "                gnn_graph.add_edge(full_emd.iloc[global_id]['tweet_id'], full_emd.iloc[e]['tweet_id'])\n",
    "\n",
    "            \n",
    "        # Check if the node has at least 10 edges    \n",
    "        elif get_degree(cm_id, node_id) < 10:\n",
    "            # include an edge to the most similar nodes\n",
    "            edges = get_more_edges(cm_id, node_id, similarity_matrix)\n",
    "            \n",
    "            for e in edges:\n",
    "                # Fix to tweetID\n",
    "                gnn_graph.add_edge(full_emd.iloc[global_id]['tweet_id'], full_emd.iloc[e]['tweet_id'])\n",
    "        else:\n",
    "              for e in get_edges(cm_id, node_id):\n",
    "                    # Fix to tweetID\n",
    "                    gnn_graph.add_edge(full_emd.iloc[global_id]['tweet_id'], full_emd.iloc[e]['tweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06c14101-da0b-40d3-9bdb-ac5406381e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(gnn_graph, \"graphLeidenFullSum.gpickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c9d449-54df-4f90-8712-66ffa4560910",
   "metadata": {},
   "source": [
    "## Select representative nodes based on centrality measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cbe4cfc-1a0f-4a3c-9fd5-cd631bb910ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new graph for each cluster\n",
    "def build_graph(df_cluster, th = 0.85):\n",
    "    cos_sub = util.cos_sim(df_cluster['clip_imgs_sum_text_embeddings'].tolist(),df_cluster['clip_imgs_sum_text_embeddings'].tolist()).detach().cpu().numpy()\n",
    "#     cos_sub = util.cos_sim(df_cluster['clip_imgs_cat_text_embeddings'].tolist(),df_cluster['clip_imgs_cat_text_embeddings'].tolist()).detach().cpu().numpy()\n",
    "    cos_sub[cos_sub < th] = 0\n",
    "    G = nx.from_numpy_array(cos_sub)\n",
    "    g = ig.Graph.from_networkx(G)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6325e8ee-e951-4a91-9f48-376f80e8834b",
   "metadata": {},
   "source": [
    "### Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8105902-b4c5-41ce-8a4d-0b8561499325",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = []\n",
    "cid = []\n",
    "for k in range(len(dict_com)):\n",
    "    g = build_graph(dict_com[k])\n",
    "    df_select.append(dict_com[k].sample(n=len(dict_com[k]), random_state=1))\n",
    "    cid.append([k]*len(dict_com[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73c55562-08bc-47f9-b1d6-0dda51386130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_select)\n",
    "df['cluster_id'] = sum(cid, [])\n",
    "df[['tweet_id', 'cluster_id']].to_csv('LeidenRandomSum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78997f83-fe5d-4e1c-bf03-19497822b8cc",
   "metadata": {},
   "source": [
    "### Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c01ecc2b-4fb3-4879-b2c2-ed152c3cf6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_centrality(g):\n",
    "    degree_inx = np.argsort(g.degree())[::-1]\n",
    "    return degree_inx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc62b634-a995-4e35-ad32-d6e6df9e5b1f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Degree centrality\n",
    "df_select = []\n",
    "cid = []\n",
    "for k in range(len(dict_com)):\n",
    "    g = build_graph(dict_com[k])\n",
    "    df_select.append(dict_com[k].iloc[degree_centrality(g)])\n",
    "    cid.append([k]*len(dict_com[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71627e24-b53b-4302-878f-cd1c45ebdd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_select)\n",
    "df['cluster_id'] = sum(cid, [])\n",
    "df[['tweet_id', 'cluster_id']].to_csv('LeidenDegreeSum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057a3e4-4031-4e11-9a1e-66b51d325ff4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "496975b3-a3d6-4a14-b6a9-61a2a38077e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank_centrality(g):\n",
    "    pagerank_inx = np.argsort(g.pagerank())[::-1]\n",
    "    return pagerank_inx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df94bdec-9e87-49df-9bac-088a20f41760",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PageRank centrality\n",
    "df_select = []\n",
    "cid = []\n",
    "for k in range(len(dict_com)):\n",
    "    g = build_graph(dict_com[k])\n",
    "    df_select.append(dict_com[k].iloc[pagerank_centrality(g)])\n",
    "    cid.append([k]*len(dict_com[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9541540-815f-41dd-a5c3-77a3bff4c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_select)\n",
    "df['cluster_id'] = sum(cid, [])\n",
    "df[['tweet_id', 'cluster_id']].to_csv('LeidenPageRankSum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d660a66d-c4ee-4ed9-9c7d-efc3b9b435ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Betweenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7602e6c2-251a-4ba0-af81-c23ef74d6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweenness_centrality(g):\n",
    "    between_inx = np.argsort(g.betweenness())[::-1]\n",
    "    return between_inx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "836294b9-1690-491d-8ac3-3f474d5caacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Betweenness centrality\n",
    "df_select = []\n",
    "cid = []\n",
    "for k in range(len(dict_com)):\n",
    "    g = build_graph(dict_com[k])\n",
    "    df_select.append(dict_com[k].iloc[betweenness_centrality(g)])\n",
    "    cid.append([k]*len(dict_com[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf7082fb-594c-4cfb-be84-3365fd4ac64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_select)\n",
    "df['cluster_id'] = sum(cid, [])\n",
    "df[['tweet_id', 'cluster_id']].to_csv('LeidenBetweennessSum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8be1c5-a397-434e-a597-f30d157cbe08",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Closeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "522d6462-4327-470f-94f0-e1520d48ffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closeness_centrality(g):\n",
    "    closeness_inx = np.argsort(g.closeness())[::-1]\n",
    "    return closeness_inx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9428b402-8d30-4779-9578-b272a1219de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = []\n",
    "cid = []\n",
    "for k in range(len(dict_com)):\n",
    "    g = build_graph(dict_com[k])\n",
    "    df_select.append(dict_com[k].iloc[closeness_centrality(g)])\n",
    "    cid.append([k]*len(dict_com[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f898e38-9d4e-4d51-afd6-e2a0c21ed750",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_select)\n",
    "df['cluster_id'] = sum(cid, [])\n",
    "df[['tweet_id', 'cluster_id']].to_csv('LeidenClosenessSum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8accfbb-dcca-4551-bf7b-8e7a4c2339d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76f92a79-50ff-4ede-bb82-97b121fb0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigenvector_centrality(g):\n",
    "    eigenvector_inx = np.argsort(g.eigenvector_centrality())[::-1]\n",
    "    return eigenvector_inx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "682cb840-cf45-4699-aae7-e3f13f359d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = []\n",
    "cid = []\n",
    "for k in range(len(dict_com)):\n",
    "    g = build_graph(dict_com[k])\n",
    "    df_select.append(dict_com[k].iloc[eigenvector_centrality(g)])\n",
    "    cid.append([k]*len(dict_com[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2853640-cabe-47bc-9758-fe2072b46c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_select)\n",
    "df['cluster_id'] = sum(cid, [])\n",
    "df[['tweet_id', 'cluster_id']].to_csv('LeidenEigenSum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb731bd-b2d0-45a2-9f92-d8c295c6692d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Multi-Centrality Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f97166-3bab-4bce-bcd0-8e5017dfbb92",
   "metadata": {},
   "source": [
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e5a41d3-60d6-4cfa-b0be-08a2d0db5de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,\"/fake-news-qa/7Set-AL/MultiCentrality/\")\n",
    "import MultiCentralityIndex as MCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f03f80eb-97cb-4f83-8165-9ec3fe75a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MCI.MCI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ebb8513-bdd0-44ca-aae7-d51cf91f435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "centralities = ['Degree', 'Pagerank', 'Eigenvector', 'Closeness', 'Betweenness', 'StructuralHoles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3df53cc-ee99-4909-9319-c95088d6b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "def mci_centrality(g, df):\n",
    "    df_mci = pd.DataFrame()\n",
    "    df_mci['tweet_id'] = df['tweet_id']\n",
    "    df_mci['MCI'] = np.zeros((len(df),1))\n",
    "    df_mci['Degree'] = sc.fit_transform(np.asarray(g.degree()).reshape(-1,1))\n",
    "    df_mci['Pagerank']=sc.fit_transform(np.asarray(g.pagerank()).reshape(-1,1))\n",
    "    df_mci['Eigenvector']=sc.fit_transform(np.asarray(g.eigenvector_centrality()).reshape(-1,1))\n",
    "    df_mci['Closeness']=sc.fit_transform(np.asarray(g.closeness()).reshape(-1,1))\n",
    "    df_mci['Betweenness']=sc.fit_transform(np.asarray(g.betweenness()).reshape(-1,1))\n",
    "    df_mci['StructuralHoles']=sc.fit_transform(np.asarray(g.constraint()).reshape(-1,1))\n",
    "    PC1 = mc.getPC1(df_mci)\n",
    "    \n",
    "    for cnt in list(centralities):\n",
    "        df_mci['MCI'] += df_mci[cnt]*PC1.loc[0,cnt] \n",
    "        \n",
    "    mci_inx = np.argsort(df_mci['MCI'])[::-1]\n",
    "    return mci_inx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae44bee8-82c6-4f48-8288-be47e236b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = []\n",
    "cid = []\n",
    "for k in range(len(dict_com)):\n",
    "    g = build_graph(dict_com[k])\n",
    "    df_select.append(dict_com[k].iloc[mci_centrality(g, dict_com[k])])\n",
    "    cid.append([k]*len(dict_com[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51d289a0-9407-4468-87ee-7e54da5a87af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_select)\n",
    "df['cluster_id'] = sum(cid, [])\n",
    "df[['tweet_id', 'cluster_id']].to_csv('LeidenMCISum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e647d5a-9e90-435f-8bb2-28988bfe9fdf",
   "metadata": {},
   "source": [
    "# Agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4bd32f2-1713-4c95-916a-69d2231ee68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8314e2ca-979b-431e-91c3-5fafaec3eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train_emd['processed_tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6eb9755c-9830-403e-bbb5-a90975bf9049",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_model = AgglomerativeClustering(n_clusters=None, distance_threshold=0.15, affinity='precomputed', linkage='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "738d3ada-3c7a-438a-925d-27965b80fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_model.fit(1-cos_copy)\n",
    "cluster_assignment = clustering_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d30e9e67-caf3-453c-b922-5b135967b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_sentences = {}\n",
    "clustered_ids = {}\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    if cluster_id not in clustered_sentences:\n",
    "        clustered_sentences[cluster_id] = []\n",
    "        clustered_ids[cluster_id] = []\n",
    "\n",
    "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
    "    clustered_ids[cluster_id].append(sentence_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "75c18be6-c23e-4d1f-b0ab-72a1199b350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = sorted(clustered_ids.items(), key= lambda x: len(x[1]), reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68bec42b-f9fc-497a-ad99-5ab0491f8f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "02394640-d6f6-4e63-8817-653210ca4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_com = {}\n",
    "k = 0\n",
    "for com in communities:\n",
    "    if (len(com[1])>=10):\n",
    "        dict_com[k] = train_emd.loc[train_emd.index[com[1]]]\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "271af4bc-6116-44a7-b274-7b1425d1c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Degree centrality\n",
    "df_select = []\n",
    "cid = []\n",
    "for k in range(len(dict_com)):\n",
    "    g = build_graph(dict_com[k])\n",
    "    df_select.append(dict_com[k].iloc[degree_centrality(g)[:10]])\n",
    "    cid.append([k]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a1f1dba-526c-496d-b44a-04a94e8ca406",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_select)\n",
    "df['cluster_id'] = sum(cid, [])\n",
    "df[['tweet_id', 'cluster_id']].to_csv('AggDegreeSum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ccd681af-ffd6-49ee-b322-e2bd4bacd171",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PageRank centrality\n",
    "df_select = []\n",
    "cid = []\n",
    "for k in range(len(dict_com)):\n",
    "    g = build_graph(dict_com[k])\n",
    "    df_select.append(dict_com[k].iloc[pagerank_centrality(g)[:10]])\n",
    "    cid.append([k]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1544ffc6-b8cc-4ca4-b636-258e30bacc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_select)\n",
    "df['cluster_id'] = sum(cid, [])\n",
    "df[['tweet_id', 'cluster_id']].to_csv('AggPageRankSum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b21425ac-c02b-4e7b-8678-e1a6d9c6caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Betweenness centrality\n",
    "df_select = []\n",
    "cid = []\n",
    "for k in range(len(dict_com)):\n",
    "    g = build_graph(dict_com[k])\n",
    "    df_select.append(dict_com[k].iloc[betweenness_centrality(g)[:10]])\n",
    "    cid.append([k]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c75f0750-6b5a-4109-9239-999bae9a9d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_select)\n",
    "df['cluster_id'] = sum(cid, [])\n",
    "df[['tweet_id', 'cluster_id']].to_csv('AggBetweennessSum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0a4708c8-14a6-4caf-8dd3-0bbebd42d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Closeness centrality\n",
    "df_select = []\n",
    "cid = []\n",
    "for k in range(len(dict_com)):\n",
    "    g = build_graph(dict_com[k])\n",
    "    df_select.append(dict_com[k].iloc[closeness_centrality(g)[:10]])\n",
    "    cid.append([k]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3270a6c8-cc58-426f-b35e-2b6e61a5ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_select)\n",
    "df['cluster_id'] = sum(cid, [])\n",
    "df[['tweet_id', 'cluster_id']].to_csv('AggClosenessSum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ae352c60-27ca-4d4a-8850-97b437d187c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eigenvector centrality\n",
    "df_select = []\n",
    "cid = []\n",
    "for k in range(len(dict_com)):\n",
    "    g = build_graph(dict_com[k])\n",
    "    df_select.append(dict_com[k].iloc[eigenvector_centrality(g)[:10]])\n",
    "    cid.append([k]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "139ba7bd-8fef-4c57-84c0-e7ef482cfb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_select)\n",
    "df['cluster_id'] = sum(cid, [])\n",
    "df[['tweet_id', 'cluster_id']].to_csv('AggEigenSum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5ab995c7-291f-428b-a2db-82aa28a89626",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MCI centrality\n",
    "df_select = []\n",
    "cid = []\n",
    "for k in range(len(dict_com)):\n",
    "    g = build_graph(dict_com[k])\n",
    "    df_select.append(dict_com[k].iloc[mci_centrality(g, dict_com[k])[:10]])\n",
    "    cid.append([k]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a9cd423d-5def-46aa-9f26-2e3973a086fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_select)\n",
    "df['cluster_id'] = sum(cid, [])\n",
    "df[['tweet_id', 'cluster_id']].to_csv('AggMCISum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fc2999b6-7e9e-449a-ab40-584b7d8ba6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random sampling\n",
    "df_select = []\n",
    "cid = []\n",
    "for k in range(len(dict_com)):\n",
    "    g = build_graph(dict_com[k])\n",
    "    df_select.append(dict_com[k].sample(n=10, random_state=1))\n",
    "    cid.append([k]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5d1ca267-19c6-40d7-bfbd-5a921e5b0395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_select)\n",
    "df['cluster_id'] = sum(cid, [])\n",
    "df[['tweet_id', 'cluster_id']].to_csv('AggRandomSum.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "russiawar",
   "language": "python",
   "name": "russiawar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
